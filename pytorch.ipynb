{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar Pytorch\n",
    "\n",
    "### Instalar Pytorch en Windows\n",
    "\n",
    "Esta es la forma más facil de instalar Pytorch en Windows y Linux\n",
    "\n",
    "```python\n",
    "pip install torch torchvision\n",
    "```\n",
    "\n",
    "Notese que nos descarga tambien torchvision, que es una libreria de Pytorch para el manejo de imagenes que usaremos más adelante.\n",
    "Pero en la página oficial de Pytorch nos encontraremos con una gran variedad de opciones para instalar Pytorch, dependiendo de la versión de Python que tengamos, de si tenemos o no una GPU, etc. Recomiendo visitar la página oficial de Pytorch para más información: https://pytorch.org/\n",
    "\n",
    "De todas formar Google Colab ya tiene instalado Pytorch con GPU, por lo que no es necesario instalarlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch es una biblioteca de programación open-source que permite a los desarrolladores realizar cómputos intensivos con tensores. Es especialmente conocida por su flexibilidad y eficiencia en la construcción y entrenamiento de modelos de deep learning. PyTorch se ha convertido en una herramienta fundamental para muchos investigadores y profesionales del aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Historia y diferencias con otras bibliotecas (como TensorFlow):\n",
    "\n",
    "* PyTorch fue desarrollado por el grupo de Inteligencia Artificial de Facebook. Su primera versión pública fue lanzada en 2017. Desde entonces, ha crecido exponencialmente en popularidad gracias a su simplicidad y versatilidad.\n",
    "* Una de las principales diferencias entre PyTorch y otras bibliotecas populares, como TensorFlow, radica en cómo manejan las operaciones de cálculo. Mientras TensorFlow emplea un enfoque de grafo computacional estático, PyTorch utiliza un grafo dinámico, lo que permite a los usuarios cambiar el comportamiento de la red 'al vuelo'. Esto hace que PyTorch sea especialmente útil para investigación y prototipos, donde se requiere experimentación constante y adaptativa.\n",
    "* Además, esta flexibilidad en PyTorch se traduce en una curva de aprendizaje más intuitiva y amigable para los principiantes, ya que pueden ver y modificar el comportamiento del modelo paso a paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casos de uso comunes (deep learning, investigación, etc.)\n",
    "\n",
    "* PyTorch es utilizado en una amplia gama de aplicaciones. En el ámbito académico, se ha convertido en una de las herramientas más populares para la investigación en deep learning debido a su flexibilidad y transparencia.\n",
    "* Industrias como la de la visión por computadora, el procesamiento de lenguaje natural y la robótica han adoptado PyTorch para construir y entrenar modelos avanzados.\n",
    "* Además de la investigación y desarrollo de modelos, PyTorch también ofrece herramientas para despliegue en producción, permitiendo a las empresas llevar soluciones basadas en inteligencia artificial al mercado de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un tensor es una generalización de escalares, vectores y matrices a un número arbitrario de dimensiones. Mientras un escalar es un número único y un vector es una lista de números, un tensor puede representar datos en 2D (como una matriz), 3D y más dimensiones.\n",
    "\n",
    "* Puedes pensar en un tensor como un contenedor multidimensional de datos. Por ejemplo, en el contexto de la visión por computadora, una imagen en color se representa comúnmente como un tensor 3D: altura, ancho y canales de color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relación entre tensores y matrices/vectores/escalares:\n",
    "\n",
    "* Un escalar es un tensor de dimensión 0 (sin dimensiones).\n",
    "* Un vector es un tensor de dimensión 1. Por ejemplo, [1, 2, 3] es un tensor 1D.\n",
    "* Una matriz es un tensor de dimensión 2. Si pensamos en una hoja de cálculo, donde tienes filas y columnas, eso sería un tensor 2D.\n",
    "* Y como mencioné, una imagen en color podría ser un tensor 3D, y así sucesivamente para datos más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, debemos importar la biblioteca de PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Creación básica de un tensor usando torch.Tensor()\n",
    "tensor_a = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor a:\")\n",
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tensor lleno de ceros\n",
    "tensor_zeros = torch.zeros(2, 3)  # Un tensor de tamaño 2x3 lleno de ceros\n",
    "print(\"\\nTensor de ceros:\")\n",
    "print(tensor_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tensor lleno de unos\n",
    "tensor_ones = torch.ones(2, 3)  # Un tensor de tamaño 2x3 lleno de unos\n",
    "print(\"\\nTensor de unos:\")\n",
    "print(tensor_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tensor con números aleatorios entre 0 y 1\n",
    "tensor_rand = torch.rand(3, 3)  # Un tensor de tamaño 3x3 con números aleatorios entre 0 y 1\n",
    "print(\"\\nTensor aleatorio:\")\n",
    "print(tensor_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Usando new_ones para crear un tensor basado en otro tensor existente\n",
    "print(\"\\nTensor original:\")\n",
    "print(tensor_a.size()) # El tamaño del tensor\n",
    "print(tensor_a)\n",
    "\n",
    "tensor_b = tensor_a.new_ones(4, 2)  # Un tensor de tamaño 4x2 lleno de unos, pero con las mismas propiedades de tensor_a\n",
    "print(\"\\nTensor creado con new_ones:\")\n",
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Usando randn_like para crear un tensor con valores aleatorios basado en las dimensiones de otro tensor\n",
    "tensor_randn = torch.randn_like(tensor_a)  # Un tensor con las mismas dimensiones que tensor_a pero lleno de números aleatorios de una distribución normal estándar (media=0, desviación estándar=1)\n",
    "print(\"\\nTensor aleatorio con randn_like:\")\n",
    "print(tensor_randn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Tensor no inicializado\n",
    "tensor_empty = torch.empty(2, 2)  # Un tensor de tamaño 2x2 no inicializado (puede contener valores residuales en memoria)\n",
    "print(\"\\nTensor vacío (sin inicializar):\")\n",
    "print(tensor_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos ejemplos te muestran varias formas de crear tensores en PyTorch. Es importante tener en cuenta que torch.empty() no inicializa el tensor con ningún valor en particular, así que puede contener valores residuales que estaban en la memoria en ese momento. Es útil cuando necesitas un tensor de ciertas dimensiones pero lo inicializarás posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Especificando el tipo de datos con dtype\n",
    "# Crear un tensor de float32\n",
    "tensor_float32 = torch.ones(2, 2, dtype=torch.float32)\n",
    "print(\"\\nTensor con dtype float32:\")\n",
    "print(tensor_float32)\n",
    "\n",
    "# Crear un tensor de int32\n",
    "tensor_int32 = torch.ones(2, 2, dtype=torch.int32)\n",
    "print(\"\\nTensor con dtype int32:\")\n",
    "print(tensor_int32)\n",
    "\n",
    "# Nota: PyTorch tiene varios dtypes disponibles, como torch.float64, torch.int16, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "\n",
    "* **dtype** en **PyTorch**: Es una especificación del tipo de dato que el tensor va a almacenar. Afecta directamente la cantidad de memoria que el tensor ocupa y la precisión de los cálculos. Elegir el dtype correcto es esencial para asegurar tanto la precisión como la eficiencia del modelo o cálculo.\n",
    "\n",
    "* **¿Por qué es importante?**: En muchos casos, especialmente en deep learning, es posible que no necesitemos la máxima precisión (como la que proporciona float64). Usar float32 o incluso float16 puede acelerar los cálculos y reducir el uso de memoria sin sacrificar demasiado la precisión o la calidad de los resultados.\n",
    "\n",
    "* Uso común en **GPUs**: Las GPUs modernas, especialmente aquellas diseñadas para deep learning, están optimizadas para ciertos dtype como float16 (también llamado half precision). Usar este dtype en lugar de float32 o float64 puede acelerar significativamente el entrenamiento de modelos en GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas con tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando algunos tensores de ejemplo\n",
    "tensor_x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "print(\"\\nTensor x:\")\n",
    "print(tensor_x)\n",
    "tensor_y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "print(\"\\nTensor y:\")\n",
    "print(tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Suma de tensores\n",
    "tensor_sum = tensor_x + tensor_y\n",
    "print(\"Suma de tensores:\")\n",
    "print(tensor_sum)\n",
    "\n",
    "# También se puede usar la función add\n",
    "tensor_sum2 = torch.add(tensor_x, tensor_y)\n",
    "print(\"\\nSuma usando torch.add:\")\n",
    "print(tensor_sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Resta de tensores\n",
    "tensor_diff = tensor_x - tensor_y\n",
    "print(\"\\nResta de tensores:\")\n",
    "print(tensor_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Multiplicación elemento a elemento (Hadamard product) https://en.wikipedia.org/wiki/Hadamard_product_(matrices)\n",
    "tensor_product = tensor_x * tensor_y\n",
    "print(\"\\nMultiplicación elemento a elemento:\")\n",
    "print(tensor_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Multiplicación matricial https://es.wikipedia.org/wiki/Multiplicaci%C3%B3n_de_matrices\n",
    "tensor_matmul = torch.matmul(tensor_x, tensor_y)\n",
    "print(\"\\nMultiplicación matricial:\")\n",
    "print(tensor_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de hacer multiplicación matricial\n",
    "tensor_matmul2 = tensor_x @ tensor_y\n",
    "print(\"\\nOtra forma de multiplicación matricial:\")\n",
    "print(tensor_matmul2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. División elemento a elemento\n",
    "tensor_div = tensor_x / tensor_y\n",
    "print(\"\\nDivisión elemento a elemento:\")\n",
    "print(tensor_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Transposición de un tensor\n",
    "tensor_transposed = tensor_x.t()\n",
    "print(\"\\nTransposición de un tensor:\")\n",
    "print(tensor_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reshape (cambio de forma) de un tensor\n",
    "tensor_reshaped = tensor_x.view(1, 4)  # Cambia el tensor a una forma de 1x4\n",
    "print(\"\\nReshape de un tensor a 1x4:\")\n",
    "print(tensor_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También se puede usar la función reshape\n",
    "tensor_reshaped2 = tensor_x.reshape(4, 1)  # Cambia el tensor a una forma de 4x1\n",
    "print(\"\\nReshape de un tensor a 4x1 usando reshape():\")\n",
    "print(tensor_reshaped2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: Diferenciación Automática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepto y necesidad del cálculo de gradientes en deep learning:\n",
    "\n",
    "* Cuando entrenamos modelos de deep learning, estamos básicamente ajustando parámetros (o pesos) para minimizar alguna forma de error o pérdida.  Para saber en qué dirección y cuánto ajustar estos parámetros, necesitamos el gradiente del error respecto a cada parámetro.\n",
    "* El gradiente nos indica la dirección en la cual cambiar un parámetro para minimizar el error, y la magnitud del gradiente nos dice cuánto de ese cambio es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo funciona Autograd?:\n",
    "\n",
    "* Autograd es el sistema en PyTorch que nos permite calcular automáticamente estos gradientes. Lo hace mediante algo llamado 'diferenciación automática', que construye un grafo computacional a medida que ejecutas operaciones. Cada nodo en este grafo es una operación, y las aristas representan tensores que fluyen entre estas operaciones.\n",
    "* Cuando solicitas el gradiente de una variable, Autograd simplemente sigue este grafo desde el nodo final hasta el nodo de la variable, aplicando la regla de la cadena de cálculo de derivadas a lo largo del camino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de requires_grad, .backward() y .grad:\n",
    "\n",
    "- `requires_grad` es un atributo de los tensores en PyTorch. Cuando lo estableces como `True`, le estás diciendo a PyTorch que deseas mantener un registro de todas las operaciones realizadas en ese tensor, para que luego puedas calcular gradientes.\n",
    "    - Por ejemplo: `x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)`.\n",
    "- Una vez que has realizado todas tus operaciones y obtenido un resultado final (por lo general, un valor de pérdida en entrenamiento de modelos), puedes llamar al método `.backward()` en ese tensor final para calcular automáticamente todos los gradientes.\n",
    "    - Ejemplo: Si `loss` es el resultado final y es un escalar, simplemente puedes hacer `loss.backward()`.\n",
    "- Después de llamar a `.backward()`, cada tensor que tenía `requires_grad` establecido en `True` tendrá un atributo `.grad` que contendrá el gradiente de ese tensor con respecto al resultado final.\n",
    "    - \"Por ejemplo: Continuando con el tensor `x` mencionado anteriormente, después de `.backward()`, `x.grad` nos dará los gradientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Notas adicionales y prácticas recomendadas:**\n",
    "- Es importante recordar que el grafo computacional se reconstruye desde cero en cada iteración. Esto significa que después de llamar a `.backward()`, el grafo se descarta para liberar memoria. Esto es útil porque en entrenamientos de deep learning, generalmente necesitamos actualizar los gradientes en cada época o iteración.\n",
    "- Si intentas ejecutar `.backward()` nuevamente sin realizar operaciones, obtendrás un error. Si necesitas conservar el grafo para múltiples llamadas a `.backward()`, puedes pasar `retain_graph=True` como argumento, aunque esto es raro y consume más memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Creación de tensores con requires_grad=True\n",
    "x = torch.tensor([2.0, 3.0, 4.0], requires_grad=True)\n",
    "y = torch.tensor([3.0, 4.0, 5.0], requires_grad=True)\n",
    "\n",
    "print(\"Tensores originales:\")\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"----------\")\n",
    "\n",
    "# 2. Realizar algunas operaciones\n",
    "z = x * y + y**2\n",
    "print(\"Resultado de operaciones en z:\")\n",
    "print(z)\n",
    "print(\"----------\")\n",
    "\n",
    "# 3. Calcular una \"pérdida\" ficticia y llamar a .backward()\n",
    "# Por simplicidad, consideraremos la suma de z como una pérdida\n",
    "loss = z.sum()\n",
    "print(\"Pérdida (suma de z):\", loss)\n",
    "print(\"----------\")\n",
    "\n",
    "# Backward para calcular gradientes\n",
    "loss.backward()\n",
    "\n",
    "# 4. Verificar los gradientes almacenados en .grad\n",
    "print(\"Gradientes:\")\n",
    "print(\"Gradiente de x:\", x.grad)  # Debería ser y (derivada de x*y con respecto a x)\n",
    "print(\"Gradiente de y:\", y.grad)  # Debería ser x + 2*y (derivada de x*y + y^2 con respecto a y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Al ejecutar este código, lo que estamos haciendo es:\n",
    "\n",
    "1. Crear dos tensores con `requires_grad=True`, lo que significa que queremos calcular gradientes con respecto a estos tensores.\n",
    "2. Realizar algunas operaciones básicas con estos tensores.\n",
    "3. Suponiendo que el resultado que obtenemos (la suma de `z`) es una pérdida que queremos minimizar, llamamos `.backward()` en esa pérdida. Esto instruye a PyTorch para calcular los gradientes de esa pérdida con respecto a todos los tensores con `requires_grad=True`.\n",
    "4. Finalmente, imprimimos estos gradientes con el atributo `.grad`.\n",
    "\n",
    "Este es un ejemplo simple pero ilustra cómo las operaciones están siendo rastreadas y cómo se pueden calcular los gradientes automáticamente con Autograd. En la práctica, en lugar de una función arbitraria como en este ejemplo, generalmente tendrías una red neuronal y una función de pérdida real, pero el principio es el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El módulo `torch.nn`:\n",
    "- `torch.nn` es el módulo en PyTorch diseñado para construir y entrenar redes neuronales. Contiene predefinidas todas las capas y funciones de pérdida que comúnmente necesitarías, simplificando enormemente el proceso de creación y entrenamiento de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de una red neuronal simple:\n",
    "- En PyTorch, una red neuronal se define como una clase que hereda de `nn.Module`. Dentro de esta clase, definimos las capas que la componen y especificamos cómo se procesarán los datos a través de ellas.\n",
    "- Por ejemplo, una red neuronal simple con una capa oculta podría definirse así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aquí, `nn.Linear` representa una capa completamente conectada. `nn.ReLU` es una función de activación, que introduce no linearidad al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass:\n",
    "- El método `forward` define cómo se procesa la entrada a través de las capas de la red. Cada vez que pasamos una entrada a través de la red (lo que se conoce como 'forward pass'), este método se ejecuta.\n",
    "- En el ejemplo anterior, la entrada `x` primero pasa a través de la capa oculta, luego a través de la función de activación ReLU, y finalmente a través de la capa de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de activación:\n",
    "\n",
    "- Las funciones de activación, como ReLU, son esenciales en redes neuronales para introducir no linearidades. Sin ellas, independientemente de cuántas capas tengas, la red seguiría siendo lineal y no podría aprender patrones complejos en los datos.\n",
    "- Existen varias funciones de activación, como `nn.ReLU`, `nn.Sigmoid`, `nn.Tanh`, y cada una tiene sus propios usos y características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con PyTorch, construir una red neuronal es un proceso intuitivo. El módulo `torch.nn` nos proporciona las herramientas para definir y entrenar modelos complejos con relativa facilidad. A medida que profundices en PyTorch, descubrirás que tiene la flexibilidad para construir desde las redes más simples hasta los modelos de aprendizaje profundo más avanzados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de una Red Neuronal Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos: DataLoader y Dataset\n",
    "\n",
    "* Entrenar una red neuronal implica proporcionarle datos en lotes y ajustar sus pesos con base en el error que produce. PyTorch facilita este proceso con sus clases Dataset y DataLoader.\n",
    "* Dataset es una clase abstracta que representa un conjunto de datos y puede ser personalizada para adaptarse a cualquier fuente de datos. Una vez que tienes tu conjunto de datos definido como un Dataset, puedes usar DataLoader para cargar eficientemente los datos en lotes, barajarlos y paralelizar la carga de datos.\n",
    "* Estas herramientas te permiten centrarte en la construcción y entrenamiento del modelo en lugar de los detalles de la carga y manipulación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando un Dataset Predefinido (por ejemplo, MNIST) con DataLoader:\n",
    "PyTorch proporciona varios conjuntos de datos comunes a través de `torchvision`. Así es cómo podrías cargar MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Transformaciones\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Dataset\n",
    "mnist_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# DataLoader\n",
    "mnist_loader = torch.utils.data.DataLoader(dataset=mnist_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Usando DataLoader en bucle de entrenamiento\n",
    "for images, labels in mnist_loader:\n",
    "    # Aquí iría el código de entrenamiento\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "```\n",
    "\n",
    "1. **`transforms.Compose()`**:\n",
    "   - Es una función de PyTorch dentro del módulo `torchvision.transforms`.\n",
    "   - Como su nombre indica, permite componer varias transformaciones juntas en una secuencia.\n",
    "   - Recibe una lista de transformaciones que se aplicarán en el orden dado.\n",
    "\n",
    "2. **`transforms.ToTensor()`**:\n",
    "   - Es una transformación de `torchvision` que convierte imágenes PIL (del módulo Python Imaging Library) o ndarrays de NumPy a tensores de PyTorch.\n",
    "   - Además, escalas las imágenes al rango [0, 1]. Es decir, si una imagen estaba en el rango de 0 a 255 (valores comunes para imágenes en formato uint8), después de `ToTensor`, los valores estarán entre 0 y 1.\n",
    "\n",
    "3. **`transforms.Normalize((0.5,), (0.5,))`**:\n",
    "   - Es otra transformación de `torchvision`.\n",
    "   - Normaliza un tensor de imagen con una media y desviación estándar dadas.\n",
    "   - En este caso, se utiliza `mean=0.5` y `std=0.5` para cada canal de la imagen. Dado que las imágenes de MNIST son en escala de grises (un solo canal), se proporciona un único valor para la media y la desviación estándar.\n",
    "   - La operación de normalización que se realiza es la siguiente: \n",
    "     ``` \n",
    "     imagen_normalizada = (imagen_original - media) / desviación_estándar\n",
    "     ```\n",
    "     En este caso, dado que tanto la media como la desviación estándar son 0.5, la operación resultante para la normalización es:\n",
    "     ``` \n",
    "     imagen_normalizada = (imagen_original - 0.5) / 0.5\n",
    "     ```\n",
    "   - Como resultado, las imágenes que originalmente estaban en el rango [0, 1] se reescalan para que sus valores estén en el rango [-1, 1].\n",
    "\n",
    "Entonces, en resumen, esa línea de código define una secuencia de transformaciones que convierte imágenes PIL o ndarrays a tensores y luego las normaliza para que sus valores estén en el rango [-1, 1]. Estas transformaciones serán aplicadas posteriormente a las imágenes del dataset MNIST cuando se carguen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creando un Dataset Personalizado:**\n",
    "Imagina que tienes datos personalizados, por ejemplo, una lista de números y deseas cargarlos en lotes. Aquí hay un ejemplo simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        # Aquí iría el código de inicialización (si es necesario)\n",
    "\n",
    "    def __len__(self): # Debe devolver el tamaño del dataset, es obligatorio implementarlo\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index): # Debe devolver un elemento del dataset basado en el índice, es obligatorio implementarlo\n",
    "        # aqui se puede hacer cualquier cosa con el elemento, como transformaciones, etc.\n",
    "        return self.data[index]\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = list(range(100))  # Una lista simple de 0 a 99\n",
    "\n",
    "# Creando el dataset personalizado\n",
    "custom_dataset = CustomDataset(data)\n",
    "\n",
    "# DataLoader\n",
    "custom_loader = DataLoader(dataset=custom_dataset, batch_size=10, shuffle=True) #¿Qué pasaría si shuffle=False?\n",
    "\n",
    "# Usando DataLoader en un bucle\n",
    "for batch in custom_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creando un Dataset Personalizado para Imágenes:\n",
    "Si tienes imágenes en un directorio y etiquetas en un archivo CSV, puedes crear un `Dataset` personalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.labels_dataframe = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.labels_dataframe.iloc[idx, 0])  # Suponiendo que el nombre de la imagen está en la primera columna\n",
    "        image = Image.open(img_name)\n",
    "        label = int(self.labels_dataframe.iloc[idx, 1])  # Suponiendo que la etiqueta está en la segunda columna\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "try:\n",
    "    dataset = ImageDataset(csv_file='labels.csv', img_dir='images/', transform=transformations)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"No se encontró el archivo labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos ejemplos muestran la flexibilidad y potencia de `Dataset` y `DataLoader` en PyTorch. Esencialmente, puedes adaptar `Dataset` para cualquier formato de datos y luego usar `DataLoader` para manejar la carga eficiente de datos en lotes durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bucles de entrenamiento y validación\n",
    "\n",
    "* Una vez que los datos están listos, entrenamos el modelo utilizando bucles de entrenamiento. En cada época (una pasada completa por el conjunto de datos), el modelo hace una predicción, calcula el error usando una función de pérdida, y ajusta sus pesos usando un optimizador.\n",
    "* Es común también tener un bucle de validación. Aquí, pasamos datos de validación (no usados en el entrenamiento) por el modelo para evaluar su desempeño. Sin embargo, durante la validación, no ajustamos los pesos del modelo. Esto nos permite verificar si el modelo está generalizando bien o si está sobreajustando al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/framework_DL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. Cargar el conjunto de datos MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 2. Definir la arquitectura MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # Aplanar la imagen (28x28 -> 784), el -1 indica que el tamaño se infiere automáticamente\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP() # Instanciar el modelo\n",
    "criterion = nn.CrossEntropyLoss() # Función de pérdida, CrossEntropyLoss para clasificación multiclase ya implementa la función softmax\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # Optimizador\n",
    "\n",
    "# 3. Bucle de entrenamiento\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad() # Reinicia los gradientes porque backward acumula los gradientes en cada iteración\n",
    "        loss.backward() # Calcula los gradientes\n",
    "        optimizer.step() # Actualiza los parámetros\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            # Epoch: es el número de veces que el modelo ha visto el conjunto de datos completo\n",
    "            # Step: es el número de veces que el modelo ha visto un batch\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Entrenamiento finalizado!\")\n",
    "\n",
    "# 4. Evaluación del modelo\n",
    "model.eval()\n",
    "with torch.no_grad(): # Deshabilita el cálculo de gradientes\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) # Obtiene el índice de la clase con mayor probabilidad\n",
    "        total += labels.size(0) # Tamaño del batch\n",
    "        correct += (predicted == labels).sum().item() # Suma el número de predicciones correctas\n",
    "\n",
    "    print(f'Precisión del modelo en las 10000 imágenes de prueba: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código configura y entrena una red neuronal multicapa simple para clasificar imágenes del conjunto de datos MNIST. Las imágenes son de 28x28 píxeles y representan dígitos escritos a mano, del 0 al 9. La red tiene dos capas ocultas y utiliza la función de activación ReLU.\n",
    "\n",
    "El modelo se entrena durante 10 épocas utilizando la función de pérdida de entropía cruzada y el optimizador SGD. Al final, se evalúa el rendimiento del modelo en el conjunto de prueba de MNIST y se imprime la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. Cargar el conjunto de datos MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "full_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
    "train_size = int(0.9 * len(full_train_dataset)) # 90% para entrenamiento\n",
    "valid_size = len(full_train_dataset) - train_size # 10% para validación\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=100, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 2. Definir la arquitectura MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # Aplanar la imagen (28x28 -> 784), el -1 indica que el tamaño se infiere automáticamente\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP() # Instanciar el modelo\n",
    "criterion = nn.CrossEntropyLoss() # Función de pérdida, CrossEntropyLoss para clasificación multiclase ya implementa la función softmax\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # Optimizador\n",
    "\n",
    "# 3. Bucle de entrenamiento\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad() # Reinicia los gradientes porque backward acumula los gradientes en cada iteración\n",
    "        loss.backward() # Calcula los gradientes\n",
    "        optimizer.step() # Actualiza los parámetros\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validación, es simplemente un forward pass con el conjunto de validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "        for images, labels in valid_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_valid += labels.size(0)\n",
    "            correct_valid += (predicted == labels).sum().item()\n",
    "    model.train() # Volver al modo de entrenamiento, esto solo es necesario en determinados casos que ya los veremos, pero es un buen hábito ponerlo siempre\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], val accuracy: {100 * correct_valid / total_valid}%')\n",
    "        \n",
    "print(\"Entrenamiento finalizado!\")\n",
    "\n",
    "# 4. Evaluación del modelo\n",
    "model.eval()\n",
    "with torch.no_grad(): # Deshabilita el cálculo de gradientes\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) # Obtiene el índice de la clase con mayor probabilidad\n",
    "        total += labels.size(0) # Tamaño del batch\n",
    "        correct += (predicted == labels).sum().item() # Suma el número de predicciones correctas\n",
    "\n",
    "    print(f'Precisión del modelo en las 10000 imágenes de prueba: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU y CUDA con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las GPUs, o Unidades de Procesamiento Gráfico, están diseñadas para realizar múltiples cálculos simultáneamente. Dado que el entrenamiento de modelos de deep learning implica muchas operaciones matemáticas repetitivas, las GPUs pueden acelerar este proceso en órdenes de magnitud en comparación con las CPUs tradicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo mover tensores y modelos a la GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyTorch hace que trabajar con GPUs sea increíblemente simple. Puedes mover un tensor o un modelo entero a la GPU usando el método .to().\n",
    "    - Por ejemplo, para mover un tensor a la GPU: tensor = tensor.to('cuda').\n",
    "    - Para mover un modelo: model = model.to('cuda').\n",
    "* Es esencial que tanto el modelo como los datos estén en la misma ubicación (ya sea CPU o GPU) durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencias entre entrenamiento en CPU vs GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mientras que la GPU puede acelerar significativamente el entrenamiento, no todo es ideal. Las GPUs tienen memoria limitada, y es posible que no puedas cargar modelos extremadamente grandes o lotes de datos muy grandes en una sola GPU.\n",
    "* Sin embargo, las ventajas suelen superar a las desventajas, especialmente para modelos más grandes y conjuntos de datos más grandes. Para problemas pequeños, la diferencia podría no ser significativa, pero a medida que escalas, las GPUs son casi siempre la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando {device} para entrenar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. Cargar el conjunto de datos MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "full_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
    "train_size = int(0.9 * len(full_train_dataset)) # 90% para entrenamiento\n",
    "valid_size = len(full_train_dataset) - train_size # 10% para validación\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=100, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 2. Definir la arquitectura MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # Aplanar la imagen (28x28 -> 784), el -1 indica que el tamaño se infiere automáticamente\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device) # Instanciar el modelo\n",
    "criterion = nn.CrossEntropyLoss().to(device) # Función de pérdida, CrossEntropyLoss para clasificación multiclase ya implementa la función softmax\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # Optimizador\n",
    "\n",
    "# 3. Bucle de entrenamiento\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Pasar al dispositivo\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ############################\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad() # Reinicia los gradientes porque backward acumula los gradientes en cada iteración\n",
    "        loss.backward() # Calcula los gradientes\n",
    "        optimizer.step() # Actualiza los parámetros\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validación, es simplemente un forward pass con el conjunto de validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "        for images, labels in valid_loader:\n",
    "            # pasar al dispositivo\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ############################\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_valid += labels.size(0)\n",
    "            correct_valid += (predicted == labels).sum().item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], val accuracy: {100 * correct_valid / total_valid}%')\n",
    "    model.train() # Volver al modo de entrenamiento, esto solo es necesario en determinados casos que ya los veremos, pero es un buen hábito ponerlo siempre\n",
    "print(\"Entrenamiento finalizado!\")\n",
    "\n",
    "# 4. Evaluación del modelo\n",
    "model.eval()\n",
    "with torch.no_grad(): # Deshabilita el cálculo de gradientes\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        # pasar al dispositivo\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ############################\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1) # Obtiene el índice de la clase con mayor probabilidad\n",
    "        total += labels.size(0) # Tamaño del batch\n",
    "        correct += (predicted == labels).sum().item() # Suma el número de predicciones correctas\n",
    "\n",
    "    print(f'Precisión del modelo en las 10000 imágenes de prueba: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios para manejar tensores\n",
    "\n",
    "Busca en la documentación de PyTorch y resuelve los siguientes ejercicios:\n",
    "\n",
    "1. Crea un tensor de 3x3 con valores de una distribución normal estándar.\n",
    "2. Crea un tensor de 4x4 con valores de una distribución uniforme entre 0 y 1.\n",
    "3. Crea un tensor de 5x5 con valores de una distribución normal con media 5 y desviación estándar de 1. \n",
    "4. Crea un tensor de 3x3 con valores de una distribución normal con media 0 y desviación estándar de 1, pero solo con valores entre 3 y 7.\n",
    "5. Crea un tensor de 3x3 con valores de una distribución normal con media 0 y desviación estándar de 1, pero solo con valores entre 3 y 7, y luego redondea los valores a enteros.\n",
    "6. Ahora convierte el tensor anterior a un tensor de tipo `long`.\n",
    "7. Crea un tensor de 5D. ¿Cómo obtendría las dimensiones del tensor?\n",
    "\n",
    "PISTA: Busca en la documentación de PyTorch las funciones `torch.randn()`, `torch.rand()`, `torch.normal()`, `torch.clamp()`, `torch.round()`, `torch.long()`, `.masked_fill` y `.shape` o `.size()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios para manejar redes neuronales\n",
    "\n",
    "1. En un notebooks aparte copia el codigo de la red neuronal simple y entrena la red neuronal con el dataset de MNIST. (Preferiblemente en Google Colab)\n",
    "2. Modifica el código para tener tambien el accuracy en el conjunto de entrenamiento.\n",
    "3. Almacena los valores de loss y accuracy en cada época.\n",
    "4. Representa en una grafica la evolución del loss de validación y de entrenamiento en función del número de épocas.\n",
    "5. Representa en una grafica la evolución del accuracy de validación y de entrenamiento en función del número de épocas.\n",
    "6. Experimenta con los hiperparametros: (Anotalos en una tabla aparte y compara los resultados obtenidos.)\n",
    "    - Número de capas ocultas\n",
    "    - Número de neuronas por capa\n",
    "    - Funciones de activación\n",
    "    - Optimizador\n",
    "    - Número de épocas\n",
    "    - Tamaño del batch\n",
    "    - etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
